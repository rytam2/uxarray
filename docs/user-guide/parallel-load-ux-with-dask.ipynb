{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26faf1b8-c7be-484b-8ca7-41da85fee2f4",
   "metadata": {},
   "source": [
    "# Load Input Data in Parallel with Dask and UXarray "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Overview\n",
    "\n",
    "This usage example demonstrates how to load unstructured input data with UXarray and Dask to minimize memory. Loading in parallel and chunking and their respective performances are also showcased.\n",
    "\n"
   ],
   "id": "e45f3a131597b27c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import uxarray as ux\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import xarray as xr\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "3a67c2959381053"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data\n",
    "\n",
    "Data loaded in this notebook is the simulated output from the Department of Energy (DOE) Energy Exascale Earth System Model (E3SM) version 2. The case is set up as an atmosphere-only (AMIP) simulation with present-day control forcing (F2010) at a 1-degree horizontal resolution (ne30pg2), where sea surface temperatures and sea ice set as default as in the E3SMv2 model. The case is run for 6 years."
   ],
   "id": "591dd9e8bdef86f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Chunking\n",
    "\n",
    "Chunks, which are small pieces of the array of interest, can be divided with Dask to be small enough to fit in memory. \n",
    "\n",
    "UXarray inherited the chunking feature from Dask, where the chunks of the data can be specified when loading. "
   ],
   "id": "c24e81987a31da0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Loading Data with Chunking\n",
    "\n",
    "The following example demonstrates loading one monthly output from E3SM. By supplying the `chunks` argument, the data loaded will be split in the way as specified in the given dictionary. In the following example, the data is split by the vertical levels in the atmosphere `vert`, as specified in the dictionary `{'vert'=4}`.\n"
   ],
   "id": "1645e716b91fd446"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_file_monthonly = \"/glade/campaign/cisl/vast/uxarray/data/e3sm_keeling/ENSO_ctl_1std/unstructured/20231220.F2010.ENSO_ctl.lagreg.ne30pg2_EC30to60E2r2.keeling.eam.h0.0006-12.nc\"\n",
    "grid_file = (\n",
    "    \"/glade/campaign/cisl/vast/uxarray/data/e3sm_keeling/E3SM_grid/ne30pg2_grd.nc\"\n",
    ")\n",
    "uxds_e3sm_mon = ux.open_dataset(grid_file, data_file_monthonly, chunks={\"lev\": 4})"
   ],
   "id": "8a0302f23f0592f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now look at one of the data arrays in the loaded dataset. \n",
    "\n",
    "By calling one of the variables `Q` - specific humidity, we can look at the data array dimensions. The full data array has 1 point in time, 72 vertical levels, and a total of 21600 faces in the simulation grid, corresponding to the single monthly we loaded, and the info shown below: `time: 1, lev: 72, n_face: 21600`. \n",
    "\n",
    "The chunk size is also shown in the second line, where they contain 4 vertical levels instead of 72 (see `chunksize=(1,4,21600)`), proving we have successfully chunked the data."
   ],
   "id": "686e9795dbbfebc9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "uxds_e3sm_mon.Q",
   "id": "6d70640b8b764c53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "UXarray also supports the same feature when loading multiple files at once with `open_mfdataset` and the same argument `chunks` as shown above. \n",
    "\n",
    "Chunk size is important as it can be significant to performance, depending on the algorithm and usage. There are multiple possible configurations for chunking, such as splitting by uniform dimension size, specific chunk shape. Chunking can also be done using the default chunking, or with the automatic chunking feature as specified in Dask with the special values `-1` for no chunking, `None` for no change in original chunking (in rechunking), and `auto` for automatic chunking to best fit the default ideal chunk size, which by default in Dask is 128MB. \n",
    "\n",
    "More details on the possible configurations and guidelines on deciding chunk size can be found on [Dask's Page about Array Chunks](https://docs.dask.org/en/stable/array-chunks.html)."
   ],
   "id": "a8d8e577ba99e72c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Loading Data with the `parallel` argument\n",
    "\n",
    "Similar to Xarray, UXarray also supports loading data in parallel. Performance may not be significant due to the chosen dataset for this notebook; and Dask client configuration requires customization depending on the data. Loading data in parallel using Dask can be helpful where the dataset of interest does not fit in memory and/or executions are to be distributed over several CPU cores or machines independently. "
   ],
   "id": "832e09eb631903b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading 6-year monthly data in serial ",
   "id": "6108d34e63406f26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%time\n",
    "# Regular Load\n",
    "data_files = \"/glade/campaign/cisl/vast/uxarray/data/e3sm_keeling/ENSO_ctl_1std/unstructured/*.nc\"\n",
    "uxds_e3sm_basic_load = ux.open_mfdataset(grid_file, data_files, parallel=False)"
   ],
   "id": "fcf60d4be476ba88"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Loading 6-year monthly data in Parallel \n",
    "The following code demonstrates setting up a local cluster with the use of 128 cores (`n_workers`), with 2 jobs (`threads_per_worker`) for each core. Using a local cluster allows multi-process computation on your local machine (e.g. laptop) and provides a diagnostic dashboard for monitoring process performances. "
   ],
   "id": "5ab768c5cc9baaed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cluster = LocalCluster(n_workers=128, threads_per_worker=2)\n",
    "client = Client(cluster)\n",
    "client"
   ],
   "id": "5e7ea5a9d32be7dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%time\n",
    "# Parallel load\n",
    "uxds_e3sm_parallel_load = ux.open_mfdataset(grid_file, data_files, parallel=True)"
   ],
   "id": "2bcb979430515e8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "uxds_e3sm_parallel_load",
   "id": "fdc67877dc708902"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Loading the data in parallel results in a 1.5x speed up. \n",
    "\n",
    "After all computations are done, it is of best practice to explicitly clean all dask workers and scheduler up by shutting down the cluster. "
   ],
   "id": "c403417c29498927"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3672699-f984-4f47-83bf-d4b8a8f55b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-uxarray-e3sm]",
   "language": "python",
   "name": "conda-env-.conda-uxarray-e3sm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
